{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentenceCompression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rTFN3kRBXtz",
        "colab_type": "text"
      },
      "source": [
        "# Basic Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzC29Z998Q-7",
        "colab_type": "text"
      },
      "source": [
        "### Load Libraries and define functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTY1l4HcBXGb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "import re\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import f1_score \n",
        "\n",
        "# Load Pytorch Libraries\n",
        "import torch\n",
        "from torch import optim\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import SequentialSampler, RandomSampler\n",
        "\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "from torch.utils.data import TensorDataset\n",
        "##@ Set Seeds\n",
        "np.random.seed(123)\n",
        "torch.manual_seed(123)\n",
        "torch.cuda.manual_seed(123)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNIq4bSowdYO",
        "colab_type": "code",
        "outputId": "b4cd353c-3e37-46c2-b55e-7b9d8fc2f6a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "# specify GPU device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "print(torch.cuda.get_device_name(0))\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime â†’ \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tesla P100-PCIE-16GB\n",
            "Sun May 24 23:07:33 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    31W / 250W |   5299MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9Z4TKKMN7-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define Functions\n",
        "\n",
        "#Define function to split words\n",
        "def splitwords(mydataframe, maxSeqLength, ReportOrderChanged = False):\n",
        "    ''' \n",
        "    Takes in my dataframe with columns \"original\" and \"summary\"\n",
        "    Returns the sentences and summaries in list of words, plus length in dataframe format\n",
        "    Also returns which sentences have word order chnaged in summary\n",
        "    '''\n",
        "    x = list(mydataframe['original'])\n",
        "    y = list(mydataframe['summary'])\n",
        "    xsplit = []\n",
        "    ysplit = []\n",
        "    xlen = []\n",
        "    ylen = []\n",
        "    labelslist = []\n",
        "    orderchanged = []\n",
        "\n",
        "    for i in range(len(x)):\n",
        "        xwords = re.findall(r\"[\\w]+|[^\\s\\w]\", x[i].lower()+'.')\n",
        "        ywords = re.findall(r\"[\\w]+|[^\\s\\w]\", y[i].lower())\n",
        "        xsplit.append(xwords)\n",
        "        ysplit.append(ywords)\n",
        "        xlen.append(len(xwords))\n",
        "        ylen.append(len(ywords))\n",
        "\n",
        "    for j in range(len(xsplit)):\n",
        "        x1 = xsplit[j]\n",
        "        y1 = ysplit[j]\n",
        "        labels = [0]*maxSeqLength\n",
        "        pointer = 0\n",
        "        for wordindex in range(len(x1)):\n",
        "            if x1[wordindex] == y1[pointer]:\n",
        "                labels[wordindex] = 1\n",
        "                pointer += 1\n",
        "            if pointer > len(y1)-1:\n",
        "                break\n",
        "            if wordindex > len(labels)-1:\n",
        "                break            \n",
        "        labelslist.append(labels)\n",
        "        if len(ysplit[j]) != sum(labels):\n",
        "            if ReportOrderChanged == True:\n",
        "                print(\"Error occured in labelling at item\", j,)\n",
        "                print(xsplit[j])\n",
        "                print(ysplit[j])\n",
        "                print(labels)\n",
        "            orderchanged.append(1)\n",
        "        else:\n",
        "            orderchanged.append(0)\n",
        "    mydataframe['xsplit'] = xsplit\n",
        "    mydataframe['ysplit'] = ysplit\n",
        "    mydataframe['xlen'] = xlen\n",
        "    mydataframe['ylen'] = ylen\n",
        "    mydataframe['labelslist'] = labelslist\n",
        "    mydataframe['orderchanged'] = orderchanged\n",
        "    return mydataframe\n",
        "\n",
        "##@ Define function to check per-sentence accuracy (i.e., how many compressions could be fully reproduced)\n",
        "'''\n",
        "Inputs: Vector of predicted values shape (m, MaxSentenceLength)\n",
        "Outputs: Sentence Accuracy, list of matches or non-matches (1s or 0s)\n",
        "'''\n",
        "def persentenceACC(predicted,labels):\n",
        "    same = []\n",
        "    for i in range(len(predicted)):\n",
        "        if np.array_equal(predicted[i], labels[i]):\n",
        "            same.append(True)\n",
        "        else:\n",
        "            same.append(False)\n",
        "    sentenceaccuracy = np.sum(same)/len(predicted)\n",
        "    return sentenceaccuracy, same"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPZIb4T28VmW",
        "colab_type": "text"
      },
      "source": [
        "### Load glove Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kr2cX6HZVjHZ",
        "colab_type": "code",
        "outputId": "15487e6a-83ae-4ba7-ef86-754cbbbb111e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "# Load glove model with pretrained embeddings\n",
        "def loadGloveModel(File):\n",
        "    print(\"Loading Glove Model\")\n",
        "    f = open(File,'r')\n",
        "    gloveModel = {}\n",
        "    counter = 0\n",
        "    for line in f:\n",
        "        # print(line)\n",
        "        # break\n",
        "        splitLines = line.split(\" \")\n",
        "        # print(splitLines)\n",
        "        word = splitLines[0]\n",
        "        wordEmbedding = np.array([float(value) for value in splitLines[1:]])\n",
        "        gloveModel[word] = wordEmbedding\n",
        "        counter += 1\n",
        "        if counter % 100000 == 0:\n",
        "            print(counter)\n",
        "    print(len(gloveModel),\" words loaded!\")\n",
        "    return gloveModel\n",
        "gloveModel = loadGloveModel(\"/content/drive/My Drive/DeepLearningProject/glove.840B.300d.txt\") ##@ This makes a dictionary of embeddings\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Glove Model\n",
            "100000\n",
            "200000\n",
            "300000\n",
            "400000\n",
            "500000\n",
            "600000\n",
            "700000\n",
            "800000\n",
            "900000\n",
            "1000000\n",
            "1100000\n",
            "1200000\n",
            "1300000\n",
            "1400000\n",
            "1500000\n",
            "1600000\n",
            "1700000\n",
            "1800000\n",
            "1900000\n",
            "2000000\n",
            "2100000\n",
            "2196016  words loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QkZ9sIJDnxu",
        "colab_type": "code",
        "outputId": "3a5cb8ff-6e11-43fd-b1a3-e6814df0b8fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## Add a vector for \"unknown\" words (https://stackoverflow.com/questions/49239941/what-is-unk-in-the-pretrained-glove-vector-files-e-g-glove-6b-50d-txt)\n",
        "unknownEmbedding = \"0.22418134 -0.28881392 0.13854356 0.00365387 -0.12870757 0.10243822 0.061626635 0.07318011 -0.061350107 -1.3477012 0.42037755 -0.063593924 -0.09683349 0.18086134 0.23704372 0.014126852 0.170096 -1.1491593 0.31497982 0.06622181 0.024687296 0.076693475 0.13851812 0.021302193 -0.06640582 -0.010336159 0.13523154 -0.042144544 -0.11938788 0.006948221 0.13333307 -0.18276379 0.052385733 0.008943111 -0.23957317 0.08500333 -0.006894406 0.0015864656 0.063391194 0.19177166 -0.13113557 -0.11295479 -0.14276934 0.03413971 -0.034278486 -0.051366422 0.18891625 -0.16673574 -0.057783455 0.036823478 0.08078679 0.022949161 0.033298038 0.011784158 0.05643189 -0.042776518 0.011959623 0.011552498 -0.0007971594 0.11300405 -0.031369694 -0.0061559738 -0.009043574 -0.415336 -0.18870236 0.13708843 0.005911723 -0.113035575 -0.030096142 -0.23908928 -0.05354085 -0.044904727 -0.20228513 0.0065645403 -0.09578946 -0.07391877 -0.06487607 0.111740574 -0.048649278 -0.16565254 -0.052037314 -0.078968436 0.13684988 0.0757494 -0.006275573 0.28693774 0.52017444 -0.0877165 -0.33010918 -0.1359622 0.114895485 -0.09744406 0.06269521 0.12118575 -0.08026362 0.35256687 -0.060017522 -0.04889904 -0.06828978 0.088740796 0.003964443 -0.0766291 0.1263925 0.07809314 -0.023164088 -0.5680669 -0.037892066 -0.1350967 -0.11351585 -0.111434504 -0.0905027 0.25174105 -0.14841858 0.034635577 -0.07334565 0.06320108 -0.038343467 -0.05413284 0.042197507 -0.090380974 -0.070528865 -0.009174437 0.009069661 0.1405178 0.02958134 -0.036431845 -0.08625681 0.042951006 0.08230793 0.0903314 -0.12279937 -0.013899368 0.048119213 0.08678239 -0.14450377 -0.04424887 0.018319942 0.015026873 -0.100526 0.06021201 0.74059093 -0.0016333034 -0.24960588 -0.023739101 0.016396184 0.11928964 0.13950661 -0.031624354 -0.01645025 0.14079992 -0.0002824564 -0.08052984 -0.0021310581 -0.025350995 0.086938225 0.14308536 0.17146006 -0.13943303 0.048792403 0.09274929 -0.053167373 0.031103406 0.012354865 0.21057427 0.32618305 0.18015954 -0.15881181 0.15322933 -0.22558987 -0.04200665 0.0084689725 0.038156632 0.15188617 0.13274793 0.113756925 -0.095273495 -0.049490947 -0.10265804 -0.27064866 -0.034567792 -0.018810693 -0.0010360252 0.10340131 0.13883452 0.21131058 -0.01981019 0.1833468 -0.10751636 -0.03128868 0.02518242 0.23232952 0.042052146 0.11731903 -0.15506615 0.0063580726 -0.15429358 0.1511722 0.12745973 0.2576985 -0.25486213 -0.0709463 0.17983761 0.054027 -0.09884228 -0.24595179 -0.093028545 -0.028203879 0.094398156 0.09233813 0.029291354 0.13110267 0.15682974 -0.016919162 0.23927948 -0.1343307 -0.22422817 0.14634751 -0.064993896 0.4703685 -0.027190214 0.06224946 -0.091360025 0.21490277 -0.19562101 -0.10032754 -0.09056772 -0.06203493 -0.18876675 -0.10963594 -0.27734384 0.12616494 -0.02217992 -0.16058226 -0.080475815 0.026953284 0.110732645 0.014894041 0.09416802 0.14299914 -0.1594008 -0.066080004 -0.007995227 -0.11668856 -0.13081996 -0.09237365 0.14741232 0.09180138 0.081735 0.3211204 -0.0036552632 -0.047030564 -0.02311798 0.048961394 0.08669574 -0.06766279 -0.50028914 -0.048515294 0.14144728 -0.032994404 -0.11954345 -0.14929578 -0.2388355 -0.019883996 -0.15917352 -0.052084364 0.2801028 -0.0029121689 -0.054581646 -0.47385484 0.17112483 -0.12066923 -0.042173345 0.1395337 0.26115036 0.012869649 0.009291686 -0.0026459037 -0.075331464 0.017840583 -0.26869613 -0.21820338 -0.17084768 -0.1022808 -0.055290595 0.13513643 0.12362477 -0.10980586 0.13980341 -0.20233242 0.08813751 0.3849736 -0.10653763 -0.06199595 0.028849555 0.03230154 0.023856193 0.069950655 0.19310954 -0.077677034 -0.144811\"\n",
        "unknownEmbedding = unknownEmbedding.split(\" \")\n",
        "len(unknownEmbedding)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50tEOrLZ8bUC",
        "colab_type": "text"
      },
      "source": [
        "### Import Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1khSeRNbBTDh",
        "colab_type": "code",
        "outputId": "deae8f41-db47-4413-835e-a4a2dffa8ea9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# Get list of files\n",
        "inputs = glob.glob(\"/content/drive/My Drive/DeepLearningProject/csv/*.csv\")\n",
        "inputs.sort()\n",
        "print(inputs)\n",
        "filename = inputs[0]\n",
        "filename2 = inputs[1]\n",
        "print(filename)\n",
        "print(filename2)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/drive/My Drive/DeepLearningProject/csv/comp-data.eval.csv', '/content/drive/My Drive/DeepLearningProject/csv/sent-comp.train01.csv', '/content/drive/My Drive/DeepLearningProject/csv/sent-comp.train02.csv', '/content/drive/My Drive/DeepLearningProject/csv/sent-comp.train03.csv', '/content/drive/My Drive/DeepLearningProject/csv/sent-comp.train04.csv', '/content/drive/My Drive/DeepLearningProject/csv/sent-comp.train05.csv', '/content/drive/My Drive/DeepLearningProject/csv/sent-comp.train06.csv', '/content/drive/My Drive/DeepLearningProject/csv/sent-comp.train07.csv', '/content/drive/My Drive/DeepLearningProject/csv/sent-comp.train08.csv', '/content/drive/My Drive/DeepLearningProject/csv/sent-comp.train09.csv', '/content/drive/My Drive/DeepLearningProject/csv/sent-comp.train10.csv']\n",
            "/content/drive/My Drive/DeepLearningProject/csv/comp-data.eval.csv\n",
            "/content/drive/My Drive/DeepLearningProject/csv/sent-comp.train01.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ncR1bYJc0nO",
        "colab_type": "code",
        "outputId": "e71cb505-775e-4a41-d1c9-4cc2a56aa618",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "# Read In Test Data\n",
        "filename = inputs[0]\n",
        "rawdatatest = pd.read_csv(filename)\n",
        "print(\"Raw test data examples:\", len(rawdatatest))\n",
        "\n",
        "# Read In Train Data\n",
        "filename2 = inputs[1]\n",
        "rawdatatrain= pd.read_csv(filename2)\n",
        "print(\"Raw train data examples:\" ,len(rawdatatrain))\n",
        "for i in range(2,len(inputs)):\n",
        "    filename2 = inputs[i]\n",
        "    print(\"Loading\",filename2)\n",
        "    rawdatanext= pd.read_csv(filename2)\n",
        "    rawdatatrain = pd.concat([rawdatatrain,rawdatanext])\n",
        "    print(\"Raw train data examples:\",len(rawdatatrain))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Raw test data examples: 10000\n",
            "Raw train data examples: 20000\n",
            "Loading /content/drive/My Drive/DeepLearningProject/csv/sent-comp.train02.csv\n",
            "Raw train data examples: 40000\n",
            "Loading /content/drive/My Drive/DeepLearningProject/csv/sent-comp.train03.csv\n",
            "Raw train data examples: 60000\n",
            "Loading /content/drive/My Drive/DeepLearningProject/csv/sent-comp.train04.csv\n",
            "Raw train data examples: 80000\n",
            "Loading /content/drive/My Drive/DeepLearningProject/csv/sent-comp.train05.csv\n",
            "Raw train data examples: 100000\n",
            "Loading /content/drive/My Drive/DeepLearningProject/csv/sent-comp.train06.csv\n",
            "Raw train data examples: 120000\n",
            "Loading /content/drive/My Drive/DeepLearningProject/csv/sent-comp.train07.csv\n",
            "Raw train data examples: 140000\n",
            "Loading /content/drive/My Drive/DeepLearningProject/csv/sent-comp.train08.csv\n",
            "Raw train data examples: 160000\n",
            "Loading /content/drive/My Drive/DeepLearningProject/csv/sent-comp.train09.csv\n",
            "Raw train data examples: 180000\n",
            "Loading /content/drive/My Drive/DeepLearningProject/csv/sent-comp.train10.csv\n",
            "Raw train data examples: 200000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIjTCTN58tjD",
        "colab_type": "text"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gEAtf2s-x7M",
        "colab_type": "text"
      },
      "source": [
        "#### Create dataframes of Train and Test sets, filter , then construct labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WE12nSnFf4pj",
        "colab_type": "code",
        "outputId": "e532d6db-7b63-4869-adb3-acf39e03dc23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "## Set max sequence length\n",
        "maxSequenceLength = 300\n",
        "\n",
        "#Test data\n",
        "testdf = splitwords(rawdatatest, maxSeqLength = 300)\n",
        "sum(testdf['orderchanged'])\n",
        "print(\"Original Data Length\", len(testdf))\n",
        "temp = sum(testdf['orderchanged'])\n",
        "print(\"Removing\", temp, \"cases where word order is changed\")\n",
        "testdf = testdf.loc[testdf['orderchanged']==0,]\n",
        "temp = sum(testdf['xlen']>maxSequenceLength)\n",
        "print(\"Removing\",temp, \"cases where sequence length > maxSequenceLength\")\n",
        "testdf = testdf.loc[testdf['xlen']<=maxSequenceLength,]\n",
        "print(\"Test data length:\",len(testdf))\n",
        "\n",
        "# Train data\n",
        "traindf = splitwords(rawdatatrain,  maxSeqLength = 300)\n",
        "sum(traindf['orderchanged'])\n",
        "print(\"Original Data Length\", len(traindf))\n",
        "temp = sum(traindf['orderchanged'])\n",
        "print(\"Removing\", temp, \"cases where word order is changed\")\n",
        "traindf = traindf.loc[traindf['orderchanged']==0,]\n",
        "temp = sum(traindf['xlen']>maxSequenceLength)\n",
        "print(\"Removing\",temp, \"cases where sequence length > maxSequenceLength\")\n",
        "traindf = traindf.loc[traindf['xlen']<=maxSequenceLength,]\n",
        "print(\"Train data length:\",len(traindf))\n",
        "traindf.head(1)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original Data Length 10000\n",
            "Removing 54 cases where word order is changed\n",
            "Removing 0 cases where sequence length > maxSequenceLength\n",
            "Test data length: 9946\n",
            "Original Data Length 200000\n",
            "Removing 1219 cases where word order is changed\n",
            "Removing 39 cases where sequence length > maxSequenceLength\n",
            "Train data length: 198742\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original</th>\n",
              "      <th>summary</th>\n",
              "      <th>xsplit</th>\n",
              "      <th>ysplit</th>\n",
              "      <th>xlen</th>\n",
              "      <th>ylen</th>\n",
              "      <th>labelslist</th>\n",
              "      <th>orderchanged</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Serge Ibaka -- the Oklahoma City Thunder forwa...</td>\n",
              "      <td>Serge Ibaka has been granted Spanish citizensh...</td>\n",
              "      <td>[serge, ibaka, -, -, the, oklahoma, city, thun...</td>\n",
              "      <td>[serge, ibaka, has, been, granted, spanish, ci...</td>\n",
              "      <td>50</td>\n",
              "      <td>13</td>\n",
              "      <td>[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            original  ... orderchanged\n",
              "0  Serge Ibaka -- the Oklahoma City Thunder forwa...  ...            0\n",
              "\n",
              "[1 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4Vmx3IP_Atd",
        "colab_type": "text"
      },
      "source": [
        "#### Create a Tokenizer based on glove embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8E4LcRtlMFp",
        "colab_type": "code",
        "outputId": "926f65d4-792b-48e0-d7dc-9d26be77000e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "##@ create tokenenizer\n",
        "tokenizer = Tokenizer(num_words = len(gloveModel.keys()),##@ Initialize Tokenizer (2196016 vocab size from glove model)\n",
        "                      oov_token='unknn') \n",
        "print(\"initialized tokenizer\")\n",
        "tokenizer.fit_on_texts(gloveModel.keys()) ##@ Increase our vocabulary (Updates internal vocabulary based on a list of texts)\n",
        "print(\"fitted tokenizer\")\n",
        "word_index = tokenizer.word_index ##@ Dict of word to index (Transforms each text in texts to a sequence of integers)\n",
        "print(\"Generated word index\")\n",
        "\n",
        "##@ Creates an array of (Vocabsize,embeddinglength), to be indexed by the word_indexer\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, 300)) \n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = gloveModel.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "embedding_matrix[word_index.get('unknn')] = np.array(unknownEmbedding) ##@ Set vector for unknown word\n",
        "print(\"Generated embedding_matrix\")\n",
        "max_features = 300\n",
        "embed_size = 300"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initialized tokenizer\n",
            "fitted tokenizer\n",
            "Generated word index\n",
            "Generated embedding_matrix\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZXzOCYa_LRV",
        "colab_type": "text"
      },
      "source": [
        "#### Tokenize train data and pad sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w72pWuM4Lxdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##@ Define my own text to sequences\n",
        "x_train = np.array(traindf['xsplit'])\n",
        "y_train = np.array(list(traindf['labelslist']))\n",
        "\n",
        "##@ Tokenize sentences\n",
        "x_train = tokenizer.texts_to_sequences(x_train)\n",
        "\n",
        "##@ Check length\n",
        "lengthcheck = []\n",
        "for i in x_train:\n",
        "    lengthcheck.append(len(i))\n",
        "traindf['checktokenizerlength'] = lengthcheck\n",
        "if sum(traindf['xlen']-traindf['checktokenizerlength']) != 0:\n",
        "    print(\"Problem with tokenizer due to sentence length!\")\n",
        "\n",
        "# Pad sequences\n",
        "x_train = sequence.pad_sequences(x_train, maxlen = max_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5MDlF8H_YSb",
        "colab_type": "text"
      },
      "source": [
        "#### Split data into training and validation (dev) sets, and construct dataloader for batch processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dS1a81W-iydv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## create training and validation split \n",
        "split = int(0.95 * len(x_train))\n",
        "index_list = list(range(len(x_train)))\n",
        "train_idx, valid_idx = index_list[:split], index_list[split:]\n",
        "\n",
        "## create iterator objects for train and valid datasets\n",
        "x_tr = torch.tensor(x_train[train_idx], dtype=torch.long)\n",
        "y_tr = torch.tensor(y_train[train_idx], dtype=torch.float32)\n",
        "train = TensorDataset(x_tr, y_tr)\n",
        "prediction_sampler = RandomSampler(train) # Random sampler\n",
        "trainloader = DataLoader(train,sampler = prediction_sampler, batch_size=128)\n",
        "\n",
        "x_val = torch.tensor(x_train[valid_idx], dtype=torch.long)\n",
        "y_val = torch.tensor(y_train[valid_idx], dtype=torch.float32)\n",
        "valid = TensorDataset(x_val, y_val)\n",
        "prediction_sampler = RandomSampler(valid) # Random sampler\n",
        "\n",
        "validloader = DataLoader(valid, sampler = prediction_sampler, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZWennyoV1qL",
        "colab_type": "text"
      },
      "source": [
        "# Construct Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tZgf053V3TD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://blog.exxactcorp.com/getting-started-with-natural-language-processing-using-pytorch/\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        \n",
        "        ## Embedding Layer, Add parameter \n",
        "        self.embedding = nn.Embedding(max_features, embed_size)   ##@ Pytorch embedding layer, read more if i can\n",
        "        et = torch.tensor(embedding_matrix, dtype=torch.float32)  ##@ makes the vector lookup array into a tensor\n",
        "        self.embedding.weight = nn.Parameter(et)                  ##@ Weights for embedding layer is the embeddings? \n",
        "        self.embedding.weight.requires_grad = False               ##@ Our glove embeddings will not be trainable\n",
        "        self.embedding_dropout = nn.Dropout2d(0.1)                ##@ guess he adds dropout for embeddings too\n",
        "        self.lstm = nn.LSTM(300, 40) \n",
        "        self.lstm2 = nn.LSTM(300, 300)      \n",
        "        self.lstm3 = nn.LSTM(300, 300, num_layers = 2, bidirectional = True, dropout = 0.1)        \n",
        "        self.linear = nn.Linear(40, 16)\n",
        "        self.linear1 = nn.Linear(600, 300)\n",
        "        self.linear2 = nn.Linear(300, 300)\n",
        "        self.linear3 = nn.Linear(1000, 500)\n",
        "        self.out = nn.Linear(16, 300)\n",
        "        self.out2 = nn.Linear(300, 300)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    # def forward(self, x):\n",
        "    #     h_embedding = self.embedding(x)        \n",
        "    #     h_lstm, _ = self.lstm(h_embedding)\n",
        "    #     max_pool, _ = torch.max(h_lstm, 1)        \n",
        "    #     linear = self.relu(self.linear(max_pool))\n",
        "    #     out = self.sigmoid(self.out(linear))\n",
        "    #     return out\n",
        "\n",
        "#My baseline\n",
        "    # def forward(self, x):\n",
        "    #     h_embedding = self.embedding(x) \n",
        "    #     h_lstm, _ = self.lstm3(h_embedding)\n",
        "    #     max_pool, _ = torch.max(h_lstm, 1)\n",
        "    #     h_linear1 = self.relu(self.linear1(max_pool))\n",
        "    #     h_linear2 = self.relu(self.linear2(h_linear1))\n",
        "    #     h_linear2 = self.relu(self.linear2(h_linear2))\n",
        "    #     h_linear2 = self.relu(self.linear2(h_linear2))\n",
        "    #     h_linear2 = self.relu(self.linear2(h_linear2))\n",
        "    #     h_linear2 = self.relu(self.linear2(h_linear2))\n",
        "    #     h_linear2 = self.relu(self.linear2(h_linear2))\n",
        "    #     h_linear2 = self.relu(self.linear2(h_linear2))\n",
        "    #     h_linear3 = self.relu(self.linear3(h_linear2)) \n",
        "    #     out = self.sigmoid(self.out2(h_linear3))\n",
        "    #     return out\n",
        "\n",
        "#My baseline 2\n",
        "    def forward(self, x):\n",
        "        h_embedding = self.embedding(x) \n",
        "        h_lstm, _ = self.lstm2(h_embedding)\n",
        "        max_pool, _ = torch.max(h_lstm, 1)\n",
        "        h_linear1 = self.relu(self.linear2(max_pool))\n",
        "        # h_linear2 = self.relu(self.linear2(h_linear1))\n",
        "        # h_linear3 = self.relu(self.linear3(h_linear2)) \n",
        "        out = self.sigmoid(self.out2(h_linear1))\n",
        "        return out\n",
        "\n",
        "model = Model()  \n",
        "\n",
        "# ##@ Test embeddings\n",
        "# embed = nn.Embedding(max_features, embed_size) \n",
        "# input1 = torch.LongTensor([[1,2,4,5],[4,3,2,9]])\n",
        "# print(input1.shape)\n",
        "# output1 = embed(input1)\n",
        "# print(output1.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c7bJJhWwB9c",
        "colab_type": "code",
        "outputId": "817c4f81-e7b5-4705-bd35-6e0dd6edee52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "##@ Put model on GPU\n",
        "model.cuda()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (embedding): Embedding(300, 300)\n",
              "  (embedding_dropout): Dropout2d(p=0.1, inplace=False)\n",
              "  (lstm): LSTM(300, 40)\n",
              "  (lstm2): LSTM(300, 300)\n",
              "  (lstm3): LSTM(300, 300, num_layers=2, dropout=0.1, bidirectional=True)\n",
              "  (linear): Linear(in_features=40, out_features=16, bias=True)\n",
              "  (linear1): Linear(in_features=600, out_features=300, bias=True)\n",
              "  (linear2): Linear(in_features=300, out_features=300, bias=True)\n",
              "  (linear3): Linear(in_features=1000, out_features=500, bias=True)\n",
              "  (out): Linear(in_features=16, out_features=300, bias=True)\n",
              "  (out2): Linear(in_features=300, out_features=300, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v38D5pN1ZcSd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##@ Define Loss Function and optimizer\n",
        "\n",
        "loss_function = nn.BCEWithLogitsLoss(reduction='mean') #https://discuss.pytorch.org/t/is-there-an-example-for-multi-class-multilabel-classification-in-pytorch/53579/11\n",
        "optimizer = optim.Adam(model.parameters(),lr=0.001) #https://pytorch.org/docs/stable/optim.html\n",
        "\n",
        "### Other things may want to try: loss\n",
        "# https://discuss.pytorch.org/t/multi-label-classification-in-pytorch/905/11"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrm5sgD_84zv",
        "colab_type": "text"
      },
      "source": [
        "### Begin Training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEK98e_asWLA",
        "colab_type": "code",
        "outputId": "7db1f78d-1050-4c18-8c7a-ff5ea623a802",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        }
      },
      "source": [
        "num_epochs = 20\n",
        "\n",
        "##@ Begin Training\n",
        "\n",
        "# Store our loss and accuracy for plotting\n",
        "train_loss_set = []\n",
        "valid_loss_set = []\n",
        "\n",
        "for epoch in range(1, num_epochs+1): ## run the model for 10 epochs\n",
        "    train_loss, valid_loss = [], []\n",
        "    ## training part \n",
        "    model.train()\n",
        "    for data, target in trainloader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        ## 1. forward propagation (Forward pass)\n",
        "        output = model(data)\n",
        "        \n",
        "        ## 2. loss calculation\n",
        "        loss = loss_function(output, target)\n",
        "        \n",
        "        ## 3. backward propagation (Backward pass)\n",
        "        loss.backward()\n",
        "        \n",
        "        ## 4. weight optimization (# Update parameters and take a step using the computed gradient)\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_loss.append(loss.item()) ##@ Each step we append to trainloss\n",
        "    train_loss_set.append(np.mean(train_loss)) ##@ Store each epoch's loss for plotting\n",
        "\n",
        "    ## evaluation part for each epoch\n",
        "    model.eval() ##@ Set model to evaluation mode\n",
        "\n",
        "    # Tracking variables \n",
        "    predictions , true_labels = [], []\n",
        "\n",
        "    for data, target in validloader:\n",
        "\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        output = model(data)\n",
        "\n",
        "        # Move output and labels to CPU\n",
        "        output = output.detach().cpu()\n",
        "        target = target.to('cpu')\n",
        "\n",
        "        loss = loss_function(output, target)\n",
        "        valid_loss.append(loss.item())\n",
        "\n",
        "         # Store predictions and true labels\n",
        "        predictions.append(output)\n",
        "        true_labels.append(target)\n",
        "\n",
        "    valid_loss_set.append(np.mean(valid_loss))\n",
        "\n",
        "    # Calculate Metrics (per epoch)\n",
        "    # SentenceAccuracy\n",
        "    temp_flat_predictions = np.array([np.array(item) for sublist in predictions for item in sublist])\n",
        "    temp_flat_predictions_binary = np.where(temp_flat_predictions > 0.5, 1, 0)\n",
        "    temp_flat_labels = np.array([np.array(item) for sublist in true_labels for item in sublist])\n",
        "\n",
        "    sentenceaccuracy, _ = persentenceACC(temp_flat_predictions_binary,temp_flat_labels)\n",
        "\n",
        "    # Word-level F1 score\n",
        "    longlistpredictions = temp_flat_predictions_binary.flatten()\n",
        "    longlistlabels = temp_flat_labels.flatten()\n",
        "    f1 = f1_score(longlistlabels,longlistpredictions)\n",
        "\n",
        "    print (\"Epoch:\", epoch, \"Training Loss: \", np.mean(train_loss), \"Valid Loss: \", np.mean(valid_loss), \"Valid SA: \",sentenceaccuracy, \"Valid F1_Score: \", f1)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 Training Loss:  0.6940699426866159 Valid Loss:  0.692131614837891 Valid SA:  0.0 Valid F1_Score:  0.4159352053526013\n",
            "Epoch: 2 Training Loss:  0.6918378797003893 Valid Loss:  0.6913560155110482 Valid SA:  0.0 Valid F1_Score:  0.45025748530283005\n",
            "Epoch: 3 Training Loss:  0.6910934980484206 Valid Loss:  0.6908937501601684 Valid SA:  0.0 Valid F1_Score:  0.44090520174357106\n",
            "Epoch: 4 Training Loss:  0.690784384887716 Valid Loss:  0.6906804427122458 Valid SA:  0.0 Valid F1_Score:  0.45305320212245004\n",
            "Epoch: 5 Training Loss:  0.6906217272850234 Valid Loss:  0.6906318825024825 Valid SA:  0.0 Valid F1_Score:  0.43497517296397675\n",
            "Epoch: 6 Training Loss:  0.6904897026334028 Valid Loss:  0.6904892126719157 Valid SA:  0.0 Valid F1_Score:  0.4649796746610775\n",
            "Epoch: 7 Training Loss:  0.6904045350264082 Valid Loss:  0.6904286016256381 Valid SA:  0.0 Valid F1_Score:  0.505043323705843\n",
            "Epoch: 8 Training Loss:  0.6903140540449277 Valid Loss:  0.6904001021996523 Valid SA:  0.0001006238679814852 Valid F1_Score:  0.48148318233407034\n",
            "Epoch: 9 Training Loss:  0.6902386242054342 Valid Loss:  0.6903936091141823 Valid SA:  0.0 Valid F1_Score:  0.5131693944404971\n",
            "Epoch: 10 Training Loss:  0.6901567318655935 Valid Loss:  0.6902827077951187 Valid SA:  0.0001006238679814852 Valid F1_Score:  0.502281698276692\n",
            "Epoch: 11 Training Loss:  0.6900879614721469 Valid Loss:  0.6902391971685947 Valid SA:  0.0 Valid F1_Score:  0.5216551966204105\n",
            "Epoch: 12 Training Loss:  0.690024068765847 Valid Loss:  0.6902123231154221 Valid SA:  0.0 Valid F1_Score:  0.48156466776649237\n",
            "Epoch: 13 Training Loss:  0.6899777836189037 Valid Loss:  0.6902540112153078 Valid SA:  0.0 Valid F1_Score:  0.5164174775036102\n",
            "Epoch: 14 Training Loss:  0.6899435340873594 Valid Loss:  0.6902045118503082 Valid SA:  0.0 Valid F1_Score:  0.4832669480871786\n",
            "Epoch: 15 Training Loss:  0.6899018640602185 Valid Loss:  0.6901475664896842 Valid SA:  0.0 Valid F1_Score:  0.5125368073525475\n",
            "Epoch: 16 Training Loss:  0.6898612443428376 Valid Loss:  0.6901276531891946 Valid SA:  0.0 Valid F1_Score:  0.5070782919522199\n",
            "Epoch: 17 Training Loss:  0.6898227650621719 Valid Loss:  0.6901167577657944 Valid SA:  0.0001006238679814852 Valid F1_Score:  0.5197602973526512\n",
            "Epoch: 18 Training Loss:  0.689794614951462 Valid Loss:  0.6901349234275329 Valid SA:  0.0 Valid F1_Score:  0.5198162737950075\n",
            "Epoch: 19 Training Loss:  0.6897645670627837 Valid Loss:  0.690102905799181 Valid SA:  0.0002012477359629704 Valid F1_Score:  0.5024586499776487\n",
            "Epoch: 20 Training Loss:  0.689735507254355 Valid Loss:  0.6901576939301614 Valid SA:  0.0 Valid F1_Score:  0.5012009504017194\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QuCi-xIwHLE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# hello"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1mZ0L5fCZvr",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UREFF_uPseTN",
        "colab_type": "code",
        "outputId": "c967c505-5b49-45d7-856c-16e2ed5fe7fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "## Plot Training and Validation Loss\n",
        "plt.figure(figsize=(15,8))\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.plot(train_loss_set)\n",
        "plt.plot(valid_loss_set)\n",
        "plt.show()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2JFP-woA0c8",
        "colab_type": "text"
      },
      "source": [
        "### Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxygr-6XsgIg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the model\n",
        "PATH = '/content/drive/My Drive/DeepLearningProject/models/basicmodel.pth'\n",
        "torch.save(model.state_dict(), PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aV7HnaGr-fDm",
        "colab_type": "text"
      },
      "source": [
        "#Predict and Evaluate on Test Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6b6D_bzA6sb",
        "colab_type": "text"
      },
      "source": [
        "### Load model weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyluxCct-Uup",
        "colab_type": "code",
        "outputId": "b1ae6fe8-79bc-423e-ec32-6720098aa285",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "### Load Model\n",
        "model2 = model\n",
        "PATH = '/content/drive/My Drive/DeepLearningProject/models/basicmodel.pth'\n",
        "model2.load_state_dict(torch.load(PATH))\n",
        "model2.cuda"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.cuda of Model(\n",
              "  (embedding): Embedding(300, 300)\n",
              "  (embedding_dropout): Dropout2d(p=0.1, inplace=False)\n",
              "  (lstm): LSTM(300, 40)\n",
              "  (lstm2): LSTM(300, 300)\n",
              "  (lstm3): LSTM(300, 300, num_layers=2, dropout=0.1, bidirectional=True)\n",
              "  (linear): Linear(in_features=40, out_features=16, bias=True)\n",
              "  (linear1): Linear(in_features=600, out_features=300, bias=True)\n",
              "  (linear2): Linear(in_features=300, out_features=300, bias=True)\n",
              "  (linear3): Linear(in_features=1000, out_features=500, bias=True)\n",
              "  (out): Linear(in_features=16, out_features=300, bias=True)\n",
              "  (out2): Linear(in_features=300, out_features=300, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (sigmoid): Sigmoid()\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjE-Rg6_AtRO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##@ Define my own text to sequences\n",
        "x_test = np.array(testdf['xsplit'])\n",
        "y_test = np.array(list(testdf['labelslist']))\n",
        "\n",
        "##@ Tokenize sentences\n",
        "x_test = tokenizer.texts_to_sequences(x_test)\n",
        "\n",
        "##@ Check length\n",
        "lengthcheck = []\n",
        "for i in x_test:\n",
        "    lengthcheck.append(len(i))\n",
        "testdf['checktokenizerlength'] = lengthcheck\n",
        "if sum(testdf['xlen']-testdf['checktokenizerlength']) != 0:\n",
        "    print(\"Problem with tokenizer due to sentence length!\")\n",
        "\n",
        "# Pad sequences\n",
        "x_test = sequence.pad_sequences(x_test, maxlen = max_features)\n",
        "\n",
        "## create iterator objects for test dataset\n",
        "x_ts = torch.tensor(x_test, dtype=torch.long)\n",
        "y_ts = torch.tensor(y_test, dtype=torch.float32)\n",
        "test = TensorDataset(x_ts, y_ts)\n",
        "prediction_sampler = SequentialSampler(test)\n",
        "testloader = DataLoader(test,sampler = prediction_sampler, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S57S-cCpXeQM",
        "colab_type": "text"
      },
      "source": [
        "### Predict on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3O0hUOFVbLZ",
        "colab_type": "code",
        "outputId": "d6e8b8de-a0c6-48ef-fe2b-a82fd0e3aee7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Put model in evaluation mode\n",
        "model2.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "for data, target in testloader:\n",
        "\n",
        "    data = data.to(device)\n",
        "    target = target.to(device)\n",
        "\n",
        "    output = model2(data)\n",
        "\n",
        "    # Move output and labels to CPU\n",
        "    output = output.detach().cpu()\n",
        "    target = target.to('cpu')\n",
        "\n",
        "    loss = loss_function(output, target)\n",
        "\n",
        "    # Store predictions and true labels\n",
        "    predictions.append(output)\n",
        "    true_labels.append(target)\n",
        "\n",
        "#  Calculate Metric\n",
        "# SentenceAccuracy\n",
        "temp_flat_predictions = np.array([np.array(item) for sublist in predictions for item in sublist])\n",
        "temp_flat_predictions_binary = np.where(temp_flat_predictions > 0.5, 1, 0)\n",
        "temp_flat_labels = np.array([np.array(item) for sublist in true_labels for item in sublist])\n",
        "\n",
        "sentenceaccuracy, _ = persentenceACC(temp_flat_predictions_binary,temp_flat_labels)\n",
        "\n",
        "# Word-level F1 score\n",
        "longlistpredictions = temp_flat_predictions_binary.flatten()\n",
        "longlistlabels = temp_flat_labels.flatten()\n",
        "f1 = f1_score(longlistlabels,longlistpredictions)\n",
        "\n",
        "print (\"SA: \",sentenceaccuracy, \"F1_Score: \", f1)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SA:  0.0 F1_Score:  0.49671230998398225\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OG79oKS0D5te",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1ee22dfa-6384-46d9-92b1-3ac18f361700"
      },
      "source": [
        "test = []\n",
        "for i in range(100):\n",
        "    randomnum = np.random.randint(2, size=2983800)\n",
        "    test.append(f1_score(longlistlabels,randomnum))\n",
        "\n",
        "print(len(test))\n",
        "np.mean(test)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0693914327570599"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUUe1XxBe0DG",
        "colab_type": "text"
      },
      "source": [
        "# Display Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mY6aO8_5XK9O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testsentences = list(testdf['xsplit'])\n",
        "\n",
        "predsentences = []\n",
        "for i in range(len(testsentences)):\n",
        "    predictedsentence = \"\"\n",
        "    for j in range(len(testsentences[i])):\n",
        "        if temp_flat_predictions_binary[i][j] == 1:\n",
        "            predictedsentence += testsentences[i][j] + \" \"\n",
        "    predsentences.append(predictedsentence)\n",
        "    \n",
        "testdf['predictedsentence'] = predsentences\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Qqks0UyYb6O",
        "colab_type": "code",
        "outputId": "11235e5a-a539-457d-d75d-ba1d1c0517e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "checkdf = testdf[['original','summary','predictedsentence']]\n",
        "checkdf.head()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original</th>\n",
              "      <th>summary</th>\n",
              "      <th>predictedsentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Five people have been taken to hospital with m...</td>\n",
              "      <td>Five people have been taken to hospital with m...</td>\n",
              "      <td>five people have been taken to hospital with</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Several school districts in Hampton Roads are ...</td>\n",
              "      <td>Several school districts are holding classes t...</td>\n",
              "      <td>several school districts in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Luis Suarez was spotted in London this afterno...</td>\n",
              "      <td>Luis Suarez was spotted in London.</td>\n",
              "      <td>luis suarez was spotted in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A woman was injured by a falling tree in the G...</td>\n",
              "      <td>A woman was injured by a falling tree.</td>\n",
              "      <td>a woman was injured by a falling tree in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Birmingham poet Benjamin Zephaniah is today le...</td>\n",
              "      <td>Benjamin Zephaniah is today leading an poetry ...</td>\n",
              "      <td>zephaniah is today leading an interactive poet...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            original  ...                                  predictedsentence\n",
              "0  Five people have been taken to hospital with m...  ...      five people have been taken to hospital with \n",
              "1  Several school districts in Hampton Roads are ...  ...                       several school districts in \n",
              "2  Luis Suarez was spotted in London this afterno...  ...                        luis suarez was spotted in \n",
              "3  A woman was injured by a falling tree in the G...  ...          a woman was injured by a falling tree in \n",
              "4  Birmingham poet Benjamin Zephaniah is today le...  ...  zephaniah is today leading an interactive poet...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJ2DfzQDj_9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkdf.to_csv('checkdf.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjg1M5_DQIIz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(999999999999999999999999999):\n",
        "    x = 10\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALpLv43CDugs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}